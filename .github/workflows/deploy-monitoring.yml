name: Deploy Monitoring

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'scratch'
        type: choice
        options:
          - scratch
          - beta
          - staging
          - prod
      include_exporters:
        description: 'Include node exporters on metagraph nodes'
        required: false
        default: true
        type: boolean
  workflow_call:
    inputs:
      environment:
        required: true
        type: string
      include_exporters:
        required: false
        type: boolean
        default: true

jobs:
  deploy:
    name: Deploy Monitoring Stack
    runs-on: ubuntu-latest

    steps:
      - name: Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.HETZNER_SSH_KEY }}" > ~/.ssh/hetzner
          chmod 600 ~/.ssh/hetzner

          for host in node1 node2 node3 services; do
            case $host in
              node1) ip="${{ secrets.HETZNER_NODE1_IP }}" ;;
              node2) ip="${{ secrets.HETZNER_NODE2_IP }}" ;;
              node3) ip="${{ secrets.HETZNER_NODE3_IP }}" ;;
              services) ip="${{ secrets.HETZNER_SERVICES_IP }}" ;;
            esac
            cat >> ~/.ssh/config << EOF
          Host $host
            HostName $ip
            User root
            IdentityFile ~/.ssh/hetzner
            StrictHostKeyChecking no
          EOF
          done

      - name: Create monitoring directories
        run: |
          ssh services << 'MKDIR'
          mkdir -p /opt/ottochain-monitoring/{prometheus/alert_rules,alertmanager,grafana/provisioning/{datasources,dashboards},loki}
          MKDIR

      - name: Write docker-compose.yml
        run: |
          ssh services "cat > /opt/ottochain-monitoring/docker-compose.yml" << 'COMPOSE_EOF'
          # OttoChain Monitoring Stack
          # Auto-generated by deploy-monitoring.yml - DO NOT EDIT ON SERVER

          services:
            prometheus:
              image: prom/prometheus:v2.50.0
              container_name: prometheus
              restart: unless-stopped
              ports:
                - "9090:9090"
              volumes:
                - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
                - ./prometheus/alert_rules:/etc/prometheus/alert_rules:ro
                - ./prometheus/recording_rules.yml:/etc/prometheus/recording_rules.yml:ro
                - prometheus_data:/prometheus
              command:
                - '--config.file=/etc/prometheus/prometheus.yml'
                - '--storage.tsdb.path=/prometheus'
                - '--storage.tsdb.retention.time=30d'
                - '--web.enable-lifecycle'
                - '--web.enable-admin-api'
              depends_on:
                - alertmanager
              networks:
                - monitoring

            alertmanager:
              image: prom/alertmanager:v0.27.0
              container_name: alertmanager
              restart: unless-stopped
              ports:
                - "9093:9093"
              volumes:
                - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
                - alertmanager_data:/alertmanager
              command:
                - '--config.file=/etc/alertmanager/alertmanager.yml'
                - '--storage.path=/alertmanager'
              networks:
                - monitoring

            grafana:
              image: grafana/grafana:10.3.1
              container_name: grafana
              restart: unless-stopped
              ports:
                - "3001:3000"
              environment:
                - GF_SECURITY_ADMIN_USER=admin
                - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
                - GF_USERS_ALLOW_SIGN_UP=false
                - GF_ALERTING_ENABLED=true
                - GF_UNIFIED_ALERTING_ENABLED=true
              volumes:
                - grafana_data:/var/lib/grafana
                - ./grafana/provisioning:/etc/grafana/provisioning:ro
              depends_on:
                - prometheus
              networks:
                - monitoring

            loki:
              image: grafana/loki:2.9.4
              container_name: loki
              restart: unless-stopped
              ports:
                - "3100:3100"
              volumes:
                - ./loki/loki-config.yml:/etc/loki/local-config.yaml:ro
                - loki_data:/loki
              command: -config.file=/etc/loki/local-config.yaml
              networks:
                - monitoring

          volumes:
            prometheus_data:
            grafana_data:
            alertmanager_data:
            loki_data:

          networks:
            monitoring:
              driver: bridge
          COMPOSE_EOF

      - name: Write prometheus.yml
        run: |
          METAGRAPH_IP="${{ secrets.HETZNER_NODE1_IP }}"
          SERVICES_IP="${{ secrets.HETZNER_SERVICES_IP }}"

          ssh services "cat > /opt/ottochain-monitoring/prometheus/prometheus.yml" << PROM_EOF
          # Auto-generated by deploy-monitoring.yml - DO NOT EDIT ON SERVER
          global:
            scrape_interval: 15s
            evaluation_interval: 15s
            external_labels:
              cluster: 'ottochain'
              env: '${{ inputs.environment }}'

          alerting:
            alertmanagers:
              - static_configs:
                  - targets: ['alertmanager:9093']

          rule_files:
            - /etc/prometheus/alert_rules/*.yml
            - /etc/prometheus/recording_rules.yml

          scrape_configs:
            - job_name: 'gl0'
              static_configs:
                - targets: ['${METAGRAPH_IP}:9000']
              metrics_path: /metrics

            - job_name: 'ml0'
              static_configs:
                - targets: ['${METAGRAPH_IP}:9200']
              metrics_path: /metrics

            - job_name: 'cl1'
              static_configs:
                - targets: ['${METAGRAPH_IP}:9300']
              metrics_path: /metrics

            - job_name: 'dl1'
              static_configs:
                - targets: ['${METAGRAPH_IP}:9400']
              metrics_path: /metrics

            - job_name: 'monitor'
              static_configs:
                - targets: ['localhost:3032']
              metrics_path: /metrics

            - job_name: 'node-services'
              static_configs:
                - targets: ['localhost:9100']
              relabel_configs:
                - source_labels: [__address__]
                  target_label: instance
                  replacement: 'services'

            - job_name: 'postgres'
              static_configs:
                - targets: ['localhost:9187']

            - job_name: 'redis'
              static_configs:
                - targets: ['localhost:9121']

            - job_name: 'node-metagraph'
              static_configs:
                - targets: ['${METAGRAPH_IP}:9100']
              relabel_configs:
                - source_labels: [__address__]
                  target_label: instance
                  replacement: 'metagraph'

            - job_name: 'prometheus'
              static_configs:
                - targets: ['localhost:9090']

            - job_name: 'alertmanager'
              static_configs:
                - targets: ['alertmanager:9093']
          PROM_EOF

      - name: Write recording rules
        run: |
          ssh services "cat > /opt/ottochain-monitoring/prometheus/recording_rules.yml" << 'RULES_EOF'
          groups:
            - name: ottochain_recording
              rules:
                - record: ottochain:node_memory_usage_percent
                  expr: 100 * (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes))
                - record: ottochain:node_cpu_usage_percent
                  expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[1m])) * 100)
                - record: ottochain:node_disk_usage_percent
                  expr: 100 * (1 - (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}))
                - record: ottochain:jvm_heap_usage_percent
                  expr: 100 * (jvm_memory_bytes_used{area="heap"} / jvm_memory_bytes_max{area="heap"})
                - record: ottochain:all_nodes_up
                  expr: min(up{job=~"gl0|ml0|cl1|dl1"})
          RULES_EOF

      - name: Write alert rules
        run: |
          # Nodes alert rules
          ssh services "cat > /opt/ottochain-monitoring/prometheus/alert_rules/nodes.yml" << 'NODES_EOF'
          groups:
            - name: tessellation-nodes
              rules:
                - alert: NodeDown
                  expr: up{job=~"gl0|ml0|cl1|dl1"} == 0
                  for: 1m
                  labels:
                    severity: critical
                  annotations:
                    summary: "{{ $labels.job }} is down"
                - alert: NodeHighHeapUsage
                  expr: ottochain:jvm_heap_usage_percent > 85
                  for: 5m
                  labels:
                    severity: warning
                  annotations:
                    summary: "{{ $labels.job }} high JVM heap usage"
                - alert: AllNodesDown
                  expr: ottochain:all_nodes_up == 0
                  for: 30s
                  labels:
                    severity: critical
                  annotations:
                    summary: "All Tessellation nodes are down!"
          NODES_EOF

          # Infrastructure alert rules
          ssh services "cat > /opt/ottochain-monitoring/prometheus/alert_rules/infrastructure.yml" << 'INFRA_EOF'
          groups:
            - name: infrastructure
              rules:
                - alert: HighMemoryUsage
                  expr: ottochain:node_memory_usage_percent > 90
                  for: 5m
                  labels:
                    severity: warning
                  annotations:
                    summary: "High memory usage on {{ $labels.instance }}"
                - alert: DiskSpaceLow
                  expr: ottochain:node_disk_usage_percent > 80
                  for: 5m
                  labels:
                    severity: warning
                  annotations:
                    summary: "Low disk space on {{ $labels.instance }}"
                - alert: HostDown
                  expr: up{job=~"node-.*"} == 0
                  for: 2m
                  labels:
                    severity: critical
                  annotations:
                    summary: "Host {{ $labels.instance }} is down"
          INFRA_EOF

          # Services alert rules
          ssh services "cat > /opt/ottochain-monitoring/prometheus/alert_rules/services.yml" << 'SVC_EOF'
          groups:
            - name: ottochain-services
              rules:
                - alert: PostgresDown
                  expr: up{job="postgres"} == 0
                  for: 1m
                  labels:
                    severity: critical
                  annotations:
                    summary: "PostgreSQL is down"
                - alert: RedisDown
                  expr: up{job="redis"} == 0
                  for: 1m
                  labels:
                    severity: critical
                  annotations:
                    summary: "Redis is down"
          SVC_EOF

      - name: Write alertmanager.yml
        run: |
          ssh services "cat > /opt/ottochain-monitoring/alertmanager/alertmanager.yml" << ALERT_EOF
          global:
            resolve_timeout: 5m

          route:
            group_by: ['alertname', 'job', 'severity']
            group_wait: 30s
            group_interval: 5m
            repeat_interval: 4h
            receiver: 'telegram'
            routes:
              - match:
                  severity: critical
                receiver: 'telegram'
                repeat_interval: 1h

          receivers:
            - name: 'telegram'
              telegram_configs:
                - bot_token: '${{ secrets.TELEGRAM_ALERT_BOT_TOKEN }}'
                  chat_id: ${{ secrets.TELEGRAM_ALERT_CHAT_ID }}
                  parse_mode: 'HTML'
                  message: |
                    {{ if eq .Status "firing" }}ðŸš¨{{ else }}âœ…{{ end }} <b>{{ .Status | toUpper }}</b>
                    <b>Alert:</b> {{ .CommonLabels.alertname }}
                    <b>Severity:</b> {{ .CommonLabels.severity }}
                    {{ range .Alerts }}{{ if .Annotations.summary }}{{ .Annotations.summary }}{{ end }}{{ end }}

          inhibit_rules:
            - source_match:
                severity: 'critical'
              target_match:
                severity: 'warning'
              equal: ['alertname', 'job']
          ALERT_EOF

      - name: Write Grafana provisioning
        run: |
          # Datasources
          ssh services "cat > /opt/ottochain-monitoring/grafana/provisioning/datasources/prometheus.yml" << 'DS_EOF'
          apiVersion: 1
          datasources:
            - name: Prometheus
              type: prometheus
              access: proxy
              url: http://prometheus:9090
              isDefault: true
              editable: false
          DS_EOF

          # Dashboards provider
          ssh services "cat > /opt/ottochain-monitoring/grafana/provisioning/dashboards/dashboards.yml" << 'DASH_EOF'
          apiVersion: 1
          providers:
            - name: 'OttoChain'
              orgId: 1
              folder: 'OttoChain'
              type: file
              disableDeletion: false
              updateIntervalSeconds: 30
              options:
                path: /etc/grafana/provisioning/dashboards
          DASH_EOF

      - name: Write Loki config
        run: |
          ssh services "cat > /opt/ottochain-monitoring/loki/loki-config.yml" << 'LOKI_EOF'
          auth_enabled: false
          server:
            http_listen_port: 3100
          common:
            path_prefix: /loki
            storage:
              filesystem:
                chunks_directory: /loki/chunks
                rules_directory: /loki/rules
            replication_factor: 1
            ring:
              kvstore:
                store: inmemory
          schema_config:
            configs:
              - from: 2020-10-24
                store: tsdb
                object_store: filesystem
                schema: v13
                index:
                  prefix: index_
                  period: 24h
          limits_config:
            retention_period: 168h
          analytics:
            reporting_enabled: false
          LOKI_EOF

      - name: Write .env
        run: |
          ssh services "cat > /opt/ottochain-monitoring/.env" << ENV_EOF
          GRAFANA_ADMIN_PASSWORD=${{ secrets.GRAFANA_ADMIN_PASSWORD }}
          ENV_EOF

      - name: Deploy stack
        run: |
          ssh services << 'DEPLOY'
          cd /opt/ottochain-monitoring
          docker compose pull
          docker compose up -d
          docker compose ps
          DEPLOY

      - name: Deploy node exporters
        if: ${{ inputs.include_exporters == true }}
        run: |
          for host in node1 node2 node3; do
            ssh $host << 'EXPORTER'
            if ! docker ps | grep -q node-exporter; then
              docker run -d --name node-exporter \
                --restart unless-stopped \
                -p 9100:9100 \
                -v /proc:/host/proc:ro \
                -v /sys:/host/sys:ro \
                -v /:/rootfs:ro \
                prom/node-exporter:latest \
                --path.procfs=/host/proc \
                --path.sysfs=/host/sys \
                --path.rootfs=/rootfs
              echo "âœ“ Node exporter installed"
            else
              echo "â„¹ Node exporter already running"
            fi
            EXPORTER
          done

      - name: Health check
        run: |
          echo "Checking monitoring stack..."
          sleep 10
          
          prom=$(ssh services "curl -sf -o /dev/null -w '%{http_code}' http://localhost:9090/-/healthy" || echo "000")
          echo "Prometheus: HTTP $prom"
          
          grafana=$(ssh services "curl -sf -o /dev/null -w '%{http_code}' http://localhost:3001/api/health" || echo "000")
          echo "Grafana: HTTP $grafana"
          
          alertmgr=$(ssh services "curl -sf -o /dev/null -w '%{http_code}' http://localhost:9093/-/healthy" || echo "000")
          echo "Alertmanager: HTTP $alertmgr"

      - name: Summary
        run: |
          echo "## ðŸ“Š Monitoring Deployment Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Service | Port | URL |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|------|-----|" >> $GITHUB_STEP_SUMMARY
          echo "| Prometheus | 9090 | http://${{ secrets.HETZNER_SERVICES_IP }}:9090 |" >> $GITHUB_STEP_SUMMARY
          echo "| Grafana | 3001 | http://${{ secrets.HETZNER_SERVICES_IP }}:3001 |" >> $GITHUB_STEP_SUMMARY
          echo "| Alertmanager | 9093 | http://${{ secrets.HETZNER_SERVICES_IP }}:9093 |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Grafana Login**: admin / (from GRAFANA_ADMIN_PASSWORD secret)" >> $GITHUB_STEP_SUMMARY
          echo "**Node Exporters**: ${{ inputs.include_exporters && 'Deployed' || 'Skipped' }}" >> $GITHUB_STEP_SUMMARY
